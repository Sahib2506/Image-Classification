{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imgae Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLbc69JPbN5Z"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-nl3SYpbhJ_",
        "outputId": "706bdfa0-89d2-4544-d5df-f692aaf64f74"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fHmepwaghBN"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpbRx5Po6iXG"
      },
      "source": [
        "base_dir = '/content/drive/MyDrive/Image Classification/Images'\n",
        "train_dir = '/content/drive/MyDrive/Image Classification/Images/Train'\n",
        "train_saree = '/content/drive/MyDrive/Image Classification/Images/Train/Saree Train'\n",
        "train_jeans = '/content/drive/MyDrive/Image Classification/Images/Train/Jeans Train'\n",
        "train_trousers = '/content/drive/MyDrive/Image Classification/Images/Train/Trouser Train'\n",
        "test_dir = '/content/drive/MyDrive/Image Classification/Images/Test'\n",
        "test_saree_dir = '/content/drive/MyDrive/Image Classification/Images/Test/Saree Test'\n",
        "test_jeans_dir = '/content/drive/MyDrive/Image Classification/Images/Test/Jeans Test'\n",
        "test_trousers_dir = '/content/drive/MyDrive/Image Classification/Images/Test/Trouser Test'\n",
        "Validation_dir = '/content/drive/MyDrive/Image Classification/Images/Validation'\n",
        "valid_saree_dir = '/content/drive/MyDrive/Image Classification/Images/Validation/Saree Validation'\n",
        "valid_jeans_dir = '/content/drive/MyDrive/Image Classification/Images/Validation/Jeans Validation'\n",
        "valid_trousers_dir = '/content/drive/MyDrive/Image Classification/Images/Validation/Trouser Validation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl28x0mQ_fff"
      },
      "source": [
        "saree_train = len(os.listdir(train_saree))\n",
        "jeans_train = len(os.listdir(train_jeans))\n",
        "trousers_train = len(os.listdir(train_trousers))\n",
        "saree_test = len(os.listdir(test_saree_dir))\n",
        "jeans_test = len(os.listdir(test_jeans_dir))\n",
        "trousers_test = len(os.listdir(test_trousers_dir))\n",
        "saree_valid = len(os.listdir(valid_saree_dir))\n",
        "jeans_valid = len(os.listdir(valid_jeans_dir))\n",
        "trousers_valid = len(os.listdir(valid_trousers_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU4yoZuhH-en"
      },
      "source": [
        "total_train = saree_train+jeans_train+trousers_train\n",
        "total_validation = saree_valid+jeans_valid+trousers_valid\n",
        "total_test = saree_test+jeans_test+trousers_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHomZ8eoBmJW"
      },
      "source": [
        "IMG_SHAPE  = 224\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ-WzcabCGXi",
        "outputId": "770f5512-70db-474b-8b56-ef32ebde0ad9"
      },
      "source": [
        "image_gen_train = ImageDataGenerator(rescale = 1./255)\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size = batch_size,\n",
        "directory = train_dir,\n",
        "shuffle= True,\n",
        "target_size = (IMG_SHAPE,IMG_SHAPE),\n",
        "class_mode = 'categorical')\n",
        "image_generator_validation = ImageDataGenerator(rescale=1./255)\n",
        "val_data_gen = image_generator_validation.flow_from_directory(batch_size=batch_size,\n",
        "directory=test_dir,\n",
        "target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "class_mode='categorical')\n",
        "image_gen_test = ImageDataGenerator(rescale=1./255)\n",
        "test_data_gen = image_gen_test.flow_from_directory(batch_size=batch_size,\n",
        "directory=Validation_dir,\n",
        "target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 491 images belonging to 3 classes.\n",
            "Found 115 images belonging to 3 classes.\n",
            "Found 114 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxyEcPVBEMI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05345ba6-a6b7-4c34-9042-bd14000bf35f"
      },
      "source": [
        "pre_trained_model = tf.keras.applications.VGG16(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58mDLbLVEs83",
        "outputId": "85ed903f-8a94-41cf-ffc0-55a831357538"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  print(layer.name)\n",
        "layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1\n",
            "block1_conv1\n",
            "block1_conv2\n",
            "block1_pool\n",
            "block2_conv1\n",
            "block2_conv2\n",
            "block2_pool\n",
            "block3_conv1\n",
            "block3_conv2\n",
            "block3_conv3\n",
            "block3_pool\n",
            "block4_conv1\n",
            "block4_conv2\n",
            "block4_conv3\n",
            "block4_pool\n",
            "block5_conv1\n",
            "block5_conv2\n",
            "block5_conv3\n",
            "block5_pool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx0gYDekFqh_"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "x = tf.keras.layers.GlobalMaxPooling2D()(last_output)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(3, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdJfRalnF1nc"
      },
      "source": [
        "model = tf.keras.Model(pre_trained_model.input, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4CekRVOGMGw"
      },
      "source": [
        "model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXeT06WAGRHJ",
        "outputId": "e9520327-da4c-4275-a5f1-d253c336df0c"
      },
      "source": [
        "vgg_classifier = model.fit(train_data_gen,\n",
        "steps_per_epoch=(total_train//batch_size),\n",
        "epochs = 5,\n",
        "validation_data=val_data_gen,\n",
        "validation_steps=(total_validation//batch_size),\n",
        "batch_size = batch_size,\n",
        "verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "15/15 - 892s - loss: 1.1471 - acc: 0.4031 - val_loss: 1.0406 - val_acc: 0.2812 - 892s/epoch - 59s/step\n",
            "Epoch 2/5\n",
            "15/15 - 882s - loss: 0.9825 - acc: 0.4619 - val_loss: 0.8958 - val_acc: 0.5625 - 882s/epoch - 59s/step\n",
            "Epoch 3/5\n",
            "15/15 - 882s - loss: 0.7377 - acc: 0.6231 - val_loss: 0.9828 - val_acc: 0.4896 - 882s/epoch - 59s/step\n",
            "Epoch 4/5\n",
            "15/15 - 903s - loss: 0.7401 - acc: 0.5991 - val_loss: 0.7613 - val_acc: 0.5729 - 903s/epoch - 60s/step\n",
            "Epoch 5/5\n",
            "15/15 - 882s - loss: 0.6512 - acc: 0.6558 - val_loss: 0.6114 - val_acc: 0.6458 - 882s/epoch - 59s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6oM4nelGXF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cf0839-b573-44b6-c6c5-1431f8dc8415"
      },
      "source": [
        "result = model.evaluate(test_data_gen,batch_size=batch_size)\n",
        "print(\"test_loss, test accuracy\",result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 56s 13s/step - loss: 0.5917 - acc: 0.7281\n",
            "test_loss, test accuracy [0.5916635394096375, 0.7280701994895935]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9x8HVcB_JVd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}